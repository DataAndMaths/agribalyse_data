# -*- coding: utf-8 -*-

##############################################################################
##############################################################################
#                                                                            #
#                         Importation des librairies                         #
#                                                                            #
##############################################################################
##############################################################################
import streamlit as st

#-----------------------------------#
# general
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#-----------------------------------#
# plotly
import plotly.express as px
import plotly.graph_objs as go
from plotly.offline import iplot, plot
from plotly.subplots import make_subplots
import plotly.figure_factory as ff
## fixer le theme
import plotly.io as pio
pio.templates.default = 'ggplot2'

#-----------------------------------#
# coefficient d'asym√©trie
from scipy.stats import skew

# pour afficher les informations g√©n√©rales sur le dataset
#from pandas_profiling import ProfileReport
#from streamlit_pandas_profiling import st_profile_report

#-----------------------------------#
# scikit-learn
## train set / test set
from sklearn.model_selection import train_test_split
## encoder
import category_encoders as ce
## preprocessing
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler
## mod√®les
from sklearn.linear_model import Ridge, SGDRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
# metrics
from sklearn.metrics import *
# model selection 
from sklearn.model_selection import learning_curve, validation_curve
# feature selection
from sklearn.feature_selection import VarianceThreshold, SelectKBest

##############################################################################
##############################################################################
#                                                                            #
#                         D√©finition des fonctions                           #
#                                                                            #
##############################################################################
##############################################################################

##############################################################################
# Fonction principale : 
# permet d'afficher les diff√©rentes pages
##############################################################################
def main():
    PAGES = {
        "Accueil": page1,
        "Exploration des donn√©es": page2,
        "Pr√©traitement des donn√©es - Premiers mod√®les - Mod√®le final": page3,
        #"Clustering" : page10
        #"R√©f√©rences" : page50
    }

    st.sidebar.title('Navigation')
    page = st.sidebar.radio("", list(PAGES.keys()))
    PAGES[page]()
    
        
##############################################################################
# Fonctions correspondant aux diff√©rentes pages
##############################################################################


#==============================   Page 1  ===================================#
#===============================  Accueil  ==================================#
def page1():
    st.title('Agribalyse')
    st.write("##")
    st.write("""
             Bienvenue !  
             
             
             """)
             
    st.markdown(":tractor:  :tractor:  :tractor:  :tractor:  :tractor:  :tractor:"+
                " :tractor:  :tractor:  :tractor:  :tractor:  :tractor:  :tractor:"+
                " :tractor:  :tractor:  :tractor:  :tractor:  :tractor:  :tractor:"+
                " :tractor:  :tractor:  :tractor:  :tractor:  :tractor:  :tractor:"+
                " :tractor:  :tractor:  :tractor:")         
    
    st.markdown(":apple:  :apple:  :apple:  :apple:  :apple:  :apple:  :apple:  :apple:"+
                ":apple:  :apple:  :apple:  :apple:  :apple:  :apple:  :apple:  :apple:"+
                ":apple:  :apple:  :apple:  :apple:  :apple:  :apple:  :apple:  :apple:"+
                ":apple:  :apple:  :apple:  :apple:")
    
    st.markdown("\U0001f956  \U0001f956  \U0001f956  \U0001f956  \U0001f956  \U0001f956  \U0001f956"+
                " \U0001f956  \U0001f956  \U0001f956  \U0001f956  \U0001f956  \U0001f956  \U0001f956"+
                " \U0001f956  \U0001f956  \U0001f956  \U0001f956  \U0001f956  \U0001f956  \U0001f956"+
                " \U0001f956  \U0001f956  \U0001f956  \U0001f956  \U0001f956  \U0001f956")

         
    st.markdown(":truck:  :truck:  :truck:  :truck:  :truck:  :truck:  :truck:"+
                " :truck:  :truck:  :truck:  :truck:  :truck:  :truck:  :truck:"+
                " :truck:  :truck:  :truck:  :truck:  :truck:  :truck:  :truck:"+
                " :truck:  :truck:  :truck:  :truck:  :truck:  :truck:")
             
    st.markdown("\U0001f6D2  \U0001f6D2  \U0001f6D2  \U0001f6D2  \U0001f6D2  \U0001f6D2 \U0001f6D2"+
                " \U0001f6D2  \U0001f6D2  \U0001f6D2  \U0001f6D2  \U0001f6D2  \U0001f6D2 \U0001f6D2"+
                " \U0001f6D2  \U0001f6D2  \U0001f6D2  \U0001f6D2  \U0001f6D2  \U0001f6D2 \U0001f6D2"+
                " \U0001f6D2  \U0001f6D2  \U0001f6D2  \U0001f6D2  \U0001f6D2  \U0001f6D2")             
    #st.markdown("\U0001f37D  \U0001f37D  \U0001f37D  \U0001f37D  \U0001f37D  \U0001f37D  \U0001f37D"+
    #            " \U0001f37D  \U0001f37D  \U0001f37D  \U0001f37D  \U0001f37D  \U0001f37D  \U0001f37D"+
    #            " \U0001f37D  \U0001f37D  \U0001f37D  \U0001f37D  \U0001f37D  \U0001f37D  \U0001f37D"+
    #            " \U0001f37D  \U0001f37D  \U0001f37D  \U0001f37D  \U0001f37D  \U0001f37D")
                
    #-------------------------------------------------------------------------#    
    st.header("Qu'est-ce qu'Agribalyse ?")   
    st.markdown("""
                [AGRIBALYSE](https://doc.agribalyse.fr/documentation/) est une
                base de donn√©es de r√©f√©rence des indicateurs d‚Äôimpacts 
                environnementaux des produits agricoles produits en France 
                et des produits alimentaires consomm√©s en France.   
                Il y a une vid√©o de pr√©sentation dans le lien. 
    """)
     
    #-------------------------------------------------------------------------#
    st.header(" Que trouve-t-on dans ces donn√©es ? \U0001f5C4")
    st.markdown("""
                Elles recensent des caract√©ristiques de plusieurs aliments 
                ainsi que les √©missions de polluants qui leur sont associ√©s.
                """)
                
     
    #-------------------------------------------------------------------------#
    st.header("Que pouvez-vous faire avec cette petite application ? ")
    st.markdown("""
                Dans la version actuelle, elle vous permet 
                * d'explorer les
                donn√©es √† l'aide essentiellement de Plotly  \U0001f642 (graphiques interactifs)
                * de construire des mod√®les pour pr√©dire le DQR en fonction de diff√©rents indicateurs.
     
                """
                )
    
    #-------------------------------------------------------------------------#
    st.header("Qu'est-ce que le DQR ?")
    st.markdown("""
                Une note de qualit√© - le **Data Quality Ratio (DQR)** - de 1, tr√®s bon, √† 5, 
                tr√®s mauvais - est associ√©e √† chaque produit agricole et alimentaire pour 
                lequel Agribalyse fournit des inventaires de cycle de vie et des 
                indicateurs d‚Äôimpacts. La Commission Europ√©enne recommande de la 
                prudence dans l‚Äôutilisation des donn√©es avec des DQR sup√©rieurs √† 3. 
                Dans la base de donn√©es AGRIBALYSE, 67 % des donn√©es ont un DQR jug√© bon 
                ou tr√®s bon (1 √† 3).
                """
                )
                
                
#==============================   Page 2  ====================================#
#========================  Exploration des donn√©es  ==========================#
def page2():
    
    
    st.sidebar.markdown("")
    
    #--S√©lection du Th√®me des graphique----#
    theme_select = st.sidebar.selectbox("Choisissez le th√®me de vos graphiques pour la suite (il y a quelques conflits avec celui de Streamlit)" ,
                                        ['ggplot2', 'seaborn', 'simple_white', 'plotly',
                                         'plotly_white', 'plotly_dark', 'presentation', 'xgridoff',
                                         'ygridoff', 'gridon', 'none'])
    
    pio.templates.default = theme_select
    #-----------------------------------#    
    
    
    
    st.title('Exploration des donn√©es')
    st.write("##")
    
    #-------------------------------------------------------------------------#
    #-------------------------------------------------------------------------#
    st.header("Sources des donn√©es")
    st.markdown("""
                [lien 1](https://www.data.gouv.fr/fr/posts/les-donnees-ouvertes-pour-lapprentissage-automatique-machine-learning/) 
                \> [lien 2](https://datascience.etalab.studio/dgml/) 
                \> [lien 3](https://datascience.etalab.studio/dgml/c763b24a-a0fe-4e77-9586-3d5453c631cd) 
                \> [lien 4](https://www.data.gouv.fr/en/datasets/agribalyse-r-detail-par-ingredient/)
    """)    

    st.write("Il y a plusieurs fichiers, nous utilisons ici la 'Synth√®se'.") 
       
    #-------------------------------------------------------------------------#    
    st.header("Donn√©es")
    
    @st.cache(persist=True)
    def load_data():
        synthese_dataset = pd.read_csv("datasets/Agribalyse_Synthese.csv", header=0)
        return synthese_dataset
    
    synthese_dataset=load_data()
    st.write(synthese_dataset)
    
    
    #*************************************************************************#
    #*************************************************************************#
    st.header("1e niveau d'exploration")
    
    #------------------------------------#
    st.subheader('Signification des variables')
    st.markdown("""
                
* La 1e partie des variables est plut√¥t explicite. 
* Pour les variables plus opaques, voir la [documentation](https://doc.agribalyse.fr/documentation/methodologie-acv).
* Voici quelques points :
    * **Score unique EF** 
        * EF = Environmental Footprint 
        * Le score unique EF est sans unit√©.
        * Plus le score est bas plus son impact sur l'environnement est faible. 
        * La valeur absolue n‚Äôest pas pertinente en tant que telle, l‚Äôint√©r√™t est la comparaison entre produit.
        * Ce score unique est une moyenne pond√©r√©e des 16 indicateurs environnementaux.
    * Une note de qualit√© - le **Data Quality Ratio (DQR)** - de 1, tr√®s bon, √† 5, 
    tr√®s mauvais - est associ√©e √† chaque produit agricole et alimentaire pour 
    lequel Agribalyse fournit des inventaires de cycle de vie et des 
    indicateurs d‚Äôimpacts. La Commission Europ√©enne recommande de la 
    prudence dans l‚Äôutilisation des donn√©es avec des DQR sup√©rieurs √† 3. 
    Dans la base de donn√©es AGRIBALYSE, 67 % des donn√©es ont un DQR jug√© bon 
    ou tr√®s bon (1 √† 3).
                """)
  
    #-------------------------------------------------------------------------#
    st.subheader('Informations g√©n√©rales')
    
    st.markdown("#### Format des donn√©es")
    st.write(synthese_dataset.shape)
    
    st.markdown("#### Identification des variables")
    st.markdown("Type des variables")
    st.write(synthese_dataset.dtypes)
    
    st.write("Variable cible :dart:")
    #target = st.selectbox("Quelle est votre variable cible ?", 
    #                      synthese_dataset.columns, 
    #                     index=11)   # variable affich√©e par defaut
    target = 'DQR - Note de qualit√© de la donn√©e (1 excellente ; 5 tr√®s faible)'
    st.markdown("La variable cible est '{}'.".format(target))
    
    
    st.markdown("#### Donn√©es manquantes")
    st.write("Il n'y a aucune donn√©e manquante.")
    st.write(pd.DataFrame(synthese_dataset.isna().sum()))
    
    
    
    
    #*************************************************************************#
    #*************************************************************************#
    st.header("2e niveau d'exploration")
    
    
    
    #-------------------------------------------------------------------------#
    st.subheader("Analyse univari√©e")
    
    #-------------------------------------------------------------------------#
    st.markdown("#### Variable continue")
    
    #-----------------------------------#
    st.markdown("##### Histogramme")
    
    var_cont = st.selectbox("S√©lectionnez une variable continue", 
                            synthese_dataset.select_dtypes(float).columns,
                            index=0)   # variable affich√©e par defaut
    
    number_bins = st.slider('Nombre de bins', min_value=4, max_value=500,
                            value=4)
    
    fig = px.histogram(synthese_dataset, x=var_cont, nbins=number_bins,
                       histnorm='probability',
                       marginal='box',
                       title='Histogramme de la variable {}'.format(var_cont))
    st.write(fig)
    
    #-----------------------------------#
    st.markdown("##### Coefficient d'asym√©trie")
    var_conts_skew = st.multiselect("S√©lectionnez les variables continues", 
                                    synthese_dataset.select_dtypes(float).columns,
                                    key='cont_skewness')  
    
    if var_conts_skew != []:
        skew_list=[]
        for col in var_conts_skew:
            skew_list.append(skew(synthese_dataset[col]))
    
        st.write(pd.DataFrame(skew_list, index=var_conts_skew))
    
    
    
    #-------------------------------------------------------------------------#
    st.markdown("#### Variable cat√©gorielle")
    var_cat = st.selectbox("S√©lectionnez une variable cat√©gorielle", 
                              synthese_dataset.select_dtypes(object).columns,
                              key="cat",
                              index=1)   # variable affich√©e par defaut
    
    fig = px.histogram(synthese_dataset, x=var_cat,
                       title='Distribution de la variable {}'.format(var_cat))
    fig.update_xaxes(categoryorder="total descending")
    st.write(fig)


    
    #-------------------------------------------------------------------------#
    st.subheader("Analyse bivari√©e")
    
    st.markdown("On analyse ici les relations avec la variable cible.") 



    #-------------------------------------------------------------------------#
    st.markdown("#### Target et Variable continue")
    
    #-----------------------------------#
    #-----------------------------------#
    st.markdown("##### Graphiques")
    
    # choisir le type de graphique
    type_cont = st.selectbox("S√©lectionnez le type de graphique", 
                              ["Scatter Matrix", "Parallel Coordinates Plot", "(option) Parallel Coordinates Plot"], 
                              index=0)    # variable affich√©e par defaut
    
    #-----------------------------------#
    if type_cont=="Scatter Matrix":
        var_cont_scatter_mat = st.selectbox("S√©lectionnez une variable continue", 
                                            synthese_dataset.select_dtypes(float).columns,
                                            key="target_cont_scatter_matr", 
                                            index=1)  # valeur par d√©faut
        if var_cont_scatter_mat !=():
            fig = px.scatter_matrix(synthese_dataset,
                                    dimensions=[target,var_cont_scatter_mat], 
                                    title='Scatter Matrix')
            # taille markers
            fig.update_traces(marker=dict(size=1))
            # enlever ou r√©duire les labels, valeurs, ticks qui rendent illisibles
            nb_col=len(var_cont_scatter_mat)  
            fig.update_layout({"xaxis" + str(i+1): dict(showticklabels=False, ticklen=0, titlefont=dict(size=(nb_col+3.8)/nb_col)) for i in range(nb_col)})
            fig.update_layout({"yaxis" + str(i+1): dict(showticklabels=False, ticklen=0, titlefont=dict(size=(nb_col+2.2)/nb_col)) for i in range(nb_col)})
            fig.update_layout(autosize=False, width=750, height=710)
            st.write(fig)
    
            # st.markdown("""*Mmm ... Petit probl√®me de labels √† r√©gler :confused:*""")
   
    #-----------------------------------#
    elif type_cont=="Parallel Coordinates Plot":
        var_cont_parallel = st.selectbox("S√©lectionnez une variable continue", 
                                         synthese_dataset.select_dtypes(float).columns, 
                                         key="cont_parallel", 
                                         index=1)    # valeur par d√©faut
        if var_cont_parallel !=[]:
            fig = px.parallel_coordinates(synthese_dataset,
                                          dimensions=[target,var_cont_parallel], 
                                          title='Parallel Coordinates Chart')
            st.write(fig)
           
    
    #-----------------------------------#
    elif type_cont=="(option) Parallel Coordinates Plot":
        var_conts_parallel = st.multiselect("S√©lectionnez des variables continues", 
                                            synthese_dataset.select_dtypes(float).columns, 
                                            key="cont_parallel"
                                            )   
        if var_conts_parallel !=[]:
            fig = px.parallel_coordinates(synthese_dataset,
                                          dimensions=var_conts_parallel, 
                                          title='Parallel Coordinates Chart')
            st.write(fig)
    
    #-----------------------------------#        
    #-----------------------------------#
    st.markdown("##### Coefficient de corr√©lation")
    
    st.write(pd.DataFrame(synthese_dataset.corr()[target].sort_values(ascending=False)))
           
    
    
    #-------------------------------------------------------------------------#
    st.markdown("#### Target et Variable Cat√©gorielle")
    
    
    
    #st.markdown(" *Malgr√© le message d'erreur quand le multiselect est vide, cela semble fonctionner ...  :confused: *")
    
    # choisir le type de graphique  
    type_cont_cat = st.selectbox("S√©lectionnez le type de graphique", 
                                 ["Box plot", "Ridgeline", "Parallel categories plot",
                                  "(option, non stable) Treemap"],
                                 key="cont_cat")
   
    
    #-----------------------------------#
    if type_cont_cat=="Box plot":
        cat2_box = st.selectbox("S√©lectionnez une variable cat√©gorielle ('Code AGB', 'Nom du Produit en Fran√ßais', 'LCI Name' ont √©t√© supprim√©es)", 
                                synthese_dataset.select_dtypes(object).drop(['Code AGB', 'Nom du Produit en Fran√ßais', 'LCI Name'], axis=1).columns,
                                key="cat2_box")
        if cat2_box != []:
            fig = px.box(synthese_dataset, 
                         x=cat2_box, 
                         y=target,
                         color=cat2_box,
                         title="Box plot")
            fig.update_layout(boxgap=0, showlegend=False)
            fig.update_xaxes(tickangle=45)
            st.write(fig) 
    
    #-----------------------------------#
    elif type_cont_cat=="Ridgeline":
        cat2_ridge = st.selectbox("S√©lectionnez une variable cat√©gorielle ('Code AGB', 'Nom du Produit en Fran√ßais', 'LCI Name' ont √©t√© supprim√©es)", 
                                  synthese_dataset.select_dtypes(object).drop(['Code AGB', 'Nom du Produit en Fran√ßais', 'LCI Name'], axis=1).columns,
                                  key="cat2_ridge")
        if cat2_ridge !=[]:
            fig = px.violin(synthese_dataset, 
                            x=target, 
                            y=cat2_ridge,
                            orientation='h', 
                            color=cat2_ridge,
                            title="Ridgeline".format(target, cat2_ridge))
            fig.update_traces(side='positive', width=2)
            fig.update_layout(showlegend=False) 
            st.write(fig)  
 
    #-----------------------------------#
    elif type_cont_cat=="Parallel categories plot":
        cat2_parallel = st.selectbox("S√©lectionnez une variable cat√©gorielle ('Code AGB', 'Nom du Produit en Fran√ßais', 'LCI Name' ont √©t√© supprim√©es)", 
                                      synthese_dataset.select_dtypes(object).drop(['Code AGB', 'Nom du Produit en Fran√ßais', 'LCI Name'], axis=1).columns,
                                      key="cat2_parallel")  
        
        if cat2_parallel !=[]:
            fig = px.parallel_categories(synthese_dataset, dimensions=[cat2_parallel], 
                                         color=target, 
                                         color_continuous_scale=px.colors.diverging.Tealrose, 
                                         color_continuous_midpoint=3)
            st.write(fig)
    
    #-----------------------------------#
    elif type_cont_cat=="(option, non stable) Treemap":
        var_cat1_cat2_tree = st.multiselect("S√©lectionnez deux variables cat√©gorielles", 
                                            synthese_dataset.select_dtypes(object).drop(['Code AGB', 'Nom du Produit en Fran√ßais', 'LCI Name'], axis=1).columns,
                                            key="cat1_cat2_tree"
                                            )
        if var_cat1_cat2_tree != []:
            fig = px.treemap(synthese_dataset,
                             path=var_cat1_cat2_tree, 
                             values=target,
                             color=target,
                             color_continuous_scale=px.colors.diverging.Tealrose,
                             color_continuous_midpoint=3,
                             title="Treemap (proportions et couleurs de la variable cible)")
            st.write(fig)
            
            
            
            
            
    #*************************************************************************#
    #*************************************************************************#
    st.header("3e niveau d'exploration")
    
            
    st.markdown("Nous analysons les corr√©lations possibles entre les variables sans la variable cible.")
            
    #-------------------------------------------------------------------------#
    st.subheader(" Entre variables num√©riques")        
   
    # colonnes type 'float' sans la variable cible
    col_float_no_target = synthese_dataset.select_dtypes(float).drop(target,axis=1).columns
    nb_col = len(col_float_no_target) 
    
    
    #-----------------------------------#
    select_conts = st.selectbox("S√©lectionnez le type de graphique",
                                ["Scatter Matrix compl√®te", "Scatter Matrix", "Clustermap", "Parallel Coordinates Plot"],
                                key="select_conts") 
    
    
    #-----------------------------------#
    if select_conts=="Scatter Matrix compl√®te":
        fig = px.scatter_matrix(synthese_dataset, dimensions=col_float_no_target,
                                title="Scatter matrix des variables num√©riques, sans la variable cible")
        fig.update_traces(marker=dict(size=1))
        fig.update_layout({"xaxis" + str(i+1): dict(showticklabels=False, ticklen=0, titlefont=dict(size=(nb_col+3.8)/nb_col)) for i in range(nb_col)})
        fig.update_layout({"yaxis" + str(i+1): dict(showticklabels=False, ticklen=0, titlefont=dict(size=(nb_col+2.2)/nb_col)) for i in range(nb_col)})
        fig.update_layout(autosize=False, width=750, height=710)
        st.write(fig)
            
    #-----------------------------------#
    elif select_conts=="Scatter Matrix":
         var_conts_scatter_mat = st.multiselect("S√©lectionnez les variables continues", 
                                                synthese_dataset.select_dtypes(float).drop(target,axis=1).columns,
                                                key="conts_scatter_matr")
         if var_conts_scatter_mat !=():
             fig = px.scatter_matrix(synthese_dataset,
                                     dimensions=var_conts_scatter_mat, 
                                     title='Scatter Matrix')
             # taille markers
             fig.update_traces(marker=dict(size=2.5))
             # enlever ou r√©duire les labels, valeurs, ticks qui rendent illisibles
             nb_col=len(var_conts_scatter_mat)  
             fig.update_layout({"xaxis" + str(i+1): dict(showticklabels=False, ticklen=0, titlefont=dict(size=(nb_col+4)/nb_col)) for i in range(nb_col)})
             fig.update_layout({"yaxis" + str(i+1): dict(showticklabels=False, ticklen=0, titlefont=dict(size=(nb_col+3)/nb_col)) for i in range(nb_col)})
             #fig.update_layout({"xaxis" : dict( titlefont=dict(size=(nb_col+3.8)/nb_col)) })
             #fig.update_layout({"yaxis" : dict( titlefont=dict(size=(nb_col+2.2)/nb_col)) })             
             fig.update_layout(autosize=False, width=750, height=710)
             st.write(fig)
    
            # st.markdown("""*Mmm ... Petit probl√®me de labels √† r√©gler :confused:*""")
   
    
    #-----------------------------------#
    elif select_conts=="Clustermap":
        fig = plt.figure()
        fig = sns.clustermap(synthese_dataset.select_dtypes(float).drop(target,axis=1).corr(),
                             cmap="vlag",
                             figsize=(15,15),
                             cbar_pos=(0.00, 0.9, 0.05, 0.18))
        st.pyplot(fig)
        
        
    #-----------------------------------#
    elif select_conts=="Parallel Coordinates Plot":
        
        var_conts_parallel = st.multiselect("S√©lectionnez les variables continues (2 ou plus)", 
                                            synthese_dataset.select_dtypes(float).drop(target,axis=1).columns, 
                                            key="conts_parallel")
        if var_conts_parallel !=[]:
            fig = px.parallel_coordinates(synthese_dataset,
                                          dimensions=var_conts_parallel, 
                                          title='Parallel Coordinates Chart')
            st.write(fig)
        
        
        
        
        
    #-------------------------------------------------------------------------#         
    st.subheader(" Entre variables cat√©gorielles")
    
    # colonnes type 'object' sans la variable cible, sans 'Nom du Produit en Fran√ßais'
    col_object_no_target = synthese_dataset.select_dtypes(object).drop('Nom du Produit en Fran√ßais', axis=1).columns
    
    
    #-----------------------------------#
    select_cats = st.selectbox("S√©lectionnez l'outil",
                              ["Histogramme", "Table de contingence"],
                              key="select_cats") 
    
    
    #-----------------------------------#
    if select_cats=="Histogramme":
        var_cats_hist = st.multiselect("S√©lectionnez les variables cat√©gorielles ('Code AGB', 'Nom du Produit en Fran√ßais', 'LCI Name' ont √©t√© supprim√©es)", 
                                       synthese_dataset.select_dtypes(object).drop(['Code AGB', 'Nom du Produit en Fran√ßais', 'LCI Name'], axis=1).columns,
                                       key="cats_hist")
        
        if var_cats_hist != []:
            cat1_h = var_cats_hist[0]
            cat2_h = var_cats_hist[1]
            fig = px.histogram(synthese_dataset, x=cat1_h, color=cat2_h, 
                               color_discrete_sequence=px.colors.qualitative.Set3)            
            st.write(fig)
    
    
    #-----------------------------------#
    elif select_cats=="Table de contingence":
        var_cats_table = st.multiselect("S√©lectionnez les variables cat√©gorielles ('Code AGB', 'Nom du Produit en Fran√ßais', 'LCI Name' ont √©t√© supprim√©es)", 
                                        synthese_dataset.select_dtypes(object).drop(['Code AGB', 'Nom du Produit en Fran√ßais', 'LCI Name'], axis=1).columns,
                                        key="cats_table")

        if var_cats_table != []:
            cat1_t = var_cats_table[0]
            cat2_t = var_cats_table[1]
            
            # table de contingence
            df = synthese_dataset[[cat1_t,cat2_t]].pivot_table(index=cat1_t,columns=cat2_t,
                                                             aggfunc=len,
                                                             # margins=True,margins_name="Total",
                                                             fill_value=0)   # remplacer les Nan par 0 
            # heatmap
            #fig = plt.figure(figsize=(22,8))
            # fig = sns.heatmap(df)   # d=integer
            
            
            fig, ax = plt.subplots()
            sns.heatmap(df, ax=ax, annot=True, fmt='d')   # d=integer
            st.write(fig)
  
            st.markdown("""*Mmm ... Affichage √† am√©liorer :confused:*""")
    
  

    #-------------------------------------------------------------------------#
    st.subheader(" Entre variables num√©riques et cat√©gorielles")        
                
    
    # colonnes type 'object' sans la variable cible, sans 'Nom du Produit en Fran√ßais'
    col_object_no_target = synthese_dataset.select_dtypes(object).drop('Nom du Produit en Fran√ßais', axis=1).columns
    # colonnes type 'float' sans la variable cible
    col_float_no_target = synthese_dataset.select_dtypes(float).drop(target, axis=1).columns
    
    
    
    #-----------------------------------#
    # choisir le type de graphique  
    type_cont_cat = st.selectbox("S√©lectionnez le type de graphique", 
                                 ["Box plot", "Ridgeline", "Parallel categories plot", "(option) Treemap"],
                                 key="cont_cat")
   
   
    
    #-----------------------------------#
    if type_cont_cat=="Box plot":
        var_cont1_cat2_box = st.multiselect("S√©lectionnez une variable continue, puis une variable cat√©gorielle ('Code AGB', 'Code CIQUAL', 'Nom du Produit en Fran√ßais', 'LCI Name' ont √©t√© supprim√©es)", 
                                            synthese_dataset.drop([target,'Code AGB', 'Code CIQUAL', 'Nom du Produit en Fran√ßais', 'LCI Name'], axis=1).columns,
                                            key="cont_1_cat2_box")
        if var_cont1_cat2_box != []:
            var_cont1_box=var_cont1_cat2_box[0]
            var_cat2_box=var_cont1_cat2_box[1]
            fig = px.box(synthese_dataset, 
                         x=var_cat2_box, 
                         y=var_cont1_box,
                         color=var_cat2_box,
                         title="{} en fonction de {}".format(var_cont1_box, var_cat2_box))
            fig.update_layout(boxgap=0, showlegend=False)
            fig.update_xaxes(tickangle=45)
            st.write(fig) 
            
            
    #-----------------------------------#
    elif type_cont_cat=="Ridgeline":
        var_cont1_cat2_ridge = st.multiselect("S√©lectionnez une variable continue, puis une variable cat√©gorielle ('Code AGB', 'Code CIQUAL', 'Nom du Produit en Fran√ßais', 'LCI Name' ont √©t√© supprim√©es)", 
                                              synthese_dataset.drop([target,'Code AGB', 'Code CIQUAL', 'Nom du Produit en Fran√ßais', 'LCI Name'], axis=1).columns,
                                              key="cont_1_cat2_ridge")
        if var_cont1_cat2_ridge !=[]:
            var_cont1_ridge=var_cont1_cat2_ridge[0]
            var_cat2_ridge=var_cont1_cat2_ridge[1]
            fig = px.violin(synthese_dataset, 
                            x=var_cont1_ridge, 
                            y=var_cat2_ridge,
                            orientation='h', 
                            color=var_cat2_ridge,
                            title="{} en fonction de {}".format(var_cont1_ridge, var_cat2_ridge))
            fig.update_traces(side='positive', width=2)
            fig.update_layout(showlegend=False) 
            st.write(fig)  
            
            
            
    #-----------------------------------#
    elif type_cont_cat=="Parallel categories plot":
        var_cont1_cat2_parallel = st.multiselect("S√©lectionnez une variable continue, puis une variable cat√©gorielle ('Code AGB', 'Code CIQUAL', 'Nom du Produit en Fran√ßais', 'LCI Name' ont √©t√© supprim√©es)", 
                                                 synthese_dataset.drop([target,'Code AGB', 'Code CIQUAL', 'Nom du Produit en Fran√ßais', 'LCI Name'], axis=1).columns,
                                                 key="cont_1_ca2_parallel")  
        
        if var_cont1_cat2_parallel !=[]:
            var_cont1_parallel=var_cont1_cat2_parallel[0]
            var_cat2_parallel=var_cont1_cat2_parallel[1]
            
            fig = px.parallel_categories(synthese_dataset, dimensions=[var_cat2_parallel], 
                                         color=var_cont1_parallel, 
                                         color_continuous_scale=px.colors.diverging.Tealrose, 
                                         color_continuous_midpoint=3)
            st.write(fig)
          
            
    #-----------------------------------#
    elif type_cont_cat=="(option) Treemap":
        var_cont1_cat2_cat3_tree = st.multiselect("S√©lectionnez une variable continue, puis deux variables cat√©gorielles ('Code AGB', 'Code CIQUAL', 'Nom du Produit en Fran√ßais', 'LCI Name' ont √©t√© supprim√©es)", 
                                                  synthese_dataset.drop([target,'Code AGB', 'Code CIQUAL', 'Nom du Produit en Fran√ßais', 'LCI Name'], axis=1).columns,
                                                  key="cont_1_cat2_cat_3_tree")
        
        if var_cont1_cat2_cat3_tree !=[]:
            cont1_tree = var_cont1_cat2_cat3_tree[0]
            cat2_tree = var_cont1_cat2_cat3_tree[1]
            cat3_tree = var_cont1_cat2_cat3_tree[2]

            fig = px.treemap(synthese_dataset,
                             path=[cat2_tree,cat3_tree],
                             values=cont1_tree,
                             color=cont1_tree,
                             title="Treemap (proportions et couleurs avec la variable continue)")
            st.write(fig) 
            
            st.markdown("""*Mmm ... Valeurs bizarres, param√©trage √† v√©rifier :confused:*""")
    
    
    #*************************************************************************#
    #*************************************************************************#
    st.header("4e niveau d'exploration")
    
    st.markdown("Apr√®s une analyse essentiellement graphique, nous compl√©tons par quelques statistiques. ")
  
    
    #-------------------------------------------------------------------------#
    st.subheader(" Entre variables num√©riques et cat√©gorielles")    
    
    st.markdown("#### Indicateur $\eta^2$")
  
    st.markdown("""
    On utilise un indicateur appel√© le **rapport de corr√©lation** $\eta^2$ :  
    * c'est un nombre compris entre 0 et 1
    * si $\eta^2$=0, il n‚Äôy a pas a priori de relation entre les variables
    * si $\eta^2$=1, il n‚Äôexiste pas a priori de relation entre les variables.
    """)
    
    with st.beta_expander("Compl√©ments"):
        st.markdown("""
                    [Formules](https://openclassrooms.com/fr/courses/4525266-decrivez-et-nettoyez-votre-jeu-de-donnees/4774896-analysez-une-variable-quantitative-et-une-qualitative-par-anova) :  
                        """)
    
        st.latex(r'''
             SCT = 
             \sum_{j} (y_{j} - \bar{y})^2
             ''')
        st.latex(r'''
             SCE = 
             \sum_j n_j (\bar{y_j} - \bar y)^2
             ''')                 
        st.latex(r''' 
             \eta^2 =
             \frac{SCE}{SCT}
             ''')
    
    
    #-----------------------------------#
    #Fonction pour calculer $\eta^2$
    #On commence par d√©finir une fonction pour calculer eta^2.
    
    # x : variable cat√©gorielle 
    # y : variable quantitative

    def eta_squared(x,y):
        # moyenne de y (y^bar)
        moyenne_y = y.mean()
    
        # on r√©cup√®re dans une liste les informations sur les classes sous forme de dictionnaire :
            # taille de la classe (n_i) et moyenne de la classe (yi^bar)
        classes = []
    
        # on fait une boucle sur les classes
        # pour chaque classe :
            # r√©cup√©rer les valeurs de y relative √† la classe ()
            # r√©cup√©rer la taille de la classe (n_i) et la moyenne de la classe (y_i^bar)
    
        for classe in x.unique():
            yi_classe = y[x==classe]
            classes.append({'ni': len(yi_classe),
                            'moyenne_classe': yi_classe.mean()})
        
        # on calcule :
            # la variation totale SCT
            # la variation interclasse SCE
        # on retourne le rapport de corr√©lation eta^2
        SCT = sum([(yj-moyenne_y)**2 for yj in y])
        SCE = sum([c['ni']*(c['moyenne_classe']-moyenne_y)**2 for c in classes])
        return SCE/SCT
    
    
    #-----------------------------------#
    st.markdown("#### Application")
    st.markdown("")
    
    var_cont1_cat2_eta2 = st.multiselect("S√©lectionnez une variable continue, puis une variable cat√©gorielle ('Code AGB', 'Code CIQUAL', 'Nom du Produit en Fran√ßais', 'LCI Name' ont √©t√© supprim√©es)", 
                                         synthese_dataset.drop(['Code AGB', 'Code CIQUAL', 'Nom du Produit en Fran√ßais', 'LCI Name'], axis=1).columns,
                                         key="cont_1_cat2_eta2") 

    if var_cont1_cat2_eta2 !=[]:
        cont1_eta = var_cont1_cat2_eta2[0]
        cat2_eta = var_cont1_cat2_eta2[1]
        st.write("{} et {} : \n{:.2f}".format(cat2_eta,cont1_eta, eta_squared(synthese_dataset[cat2_eta], synthese_dataset[cont1_eta])))
    
    


    #-------------------------------------------------------------------------#
    st.subheader("Entre variables cat√©gorielles")    
    
    st.markdown("#### Table de contingence avec indicateur de d√©pendance")
  
    st.markdown("")
    st.markdown("""
    Ici, on ne peut pas utiliser le test du khi2 vu que la condition asymptotique n'est pas v√©rifi√©e (ie : les effectifs ne sont pas tous sup√©rieurs √† 5).  
    Nous allons colorer les cases non pas avec l'effectif mais avec une valeur qui donne une indication sur l'ind√©pendence des deux variables.   
    
    Les id√©es :
    * on mesure l'√©cart entre l'effectif observ√©e (une cellule de la table) et l'effectif attendu en cas d'ind√©pendance (produit des deux totaux divis√© par l'effectif total) 
    * on transforme pour avoir un nombre entre 0 et 1 
    * on peut voir ce nombre comme une contribution √† la non-ind√©pendance des deux variables 
    * plus la case est claire, plus la case est source de non-ind√©pendance.   
    """)
    
    with st.beta_expander("Compl√©ments"):
        st.markdown("""
    [Formules](https://openclassrooms.com/fr/courses/4525266-decrivez-et-nettoyez-votre-jeu-de-donnees/4775616-analysez-deux-variables-qualitatives-avec-le-chi-2) :
                """) 
                
    #st.latex(r'''
    #         une cellule de la table $n_{ij}
    #         ''')
    #st.latex(r'''
    #         \frac{n_{i.} n_{.j}}{n} 
    #         ''')
            
    #st.latex(r'''
    #         n_{ij} - \frac{n_{i.} n_{.j}}{n}
    #         ''')

    #st.latex(r'''
    #        (n_{ij} - \frac{n_{i.} n_{.j}}{n})^2
    #         ''')
            
        st.latex(r'''
                 \xi_{ij} = \frac{(n_{ij} - \frac{n_{i.} n_{.j}}{n})^2}{ \frac{n_{i.} n_{.j}}{n}}
                 ''')
            
        st.latex(r'''
                 \xi_n = \sum_i \sum_j\xi_{ij}
                 ''')
            
            
        st.latex(r'''
                 {\xi_{ij}}_{normalis√©} = \frac {\xi_{ij}}{\xi_n}
                 ''')
            
  
    #-----------------------------------#
    #Fonction pour construire la table avec indicateur de d√©pendance
    
    # construisons d'abord une fonction 
    # qui prend : (1) le dataset (2) les deux variables cat√©gorielles
    # et retourne : (1) la table de contingence (2) la table des xi_{ij} normalis√©e

    def table_xi_normalisee(dataset, var1, var2):
        # table de contingence  
        # on rajoute totaux 
        # on remplace les NaN par 0
        cont = dataset[[var1, var2]].pivot_table(index=var1, columns=var2, 
                                                 aggfunc=len,
                                                 margins=True, margins_name="Total").fillna(0) 

        tx = cont.loc[:,["Total"]]         # total en colonne
        ty = cont.loc[["Total"],:]         # total\sum_j (\hat{y_j} - \bar y)^2 en ligne
        n = len(dataset)                   # effectif total
        indep = tx.dot(ty) / n             # produit des deux totaux divis√© par l'effectif total  ùëõ_ùëñ. * ùëõ_.ùëó / ùëõ  
        
        measure = (cont-indep)**2/indep    # xi_{ij}
        xi_n = measure.sum().sum()
        table = measure/xi_n               # xi_{ij} normalis√©
    
        return cont, table

        # notons qu'on obtient des couleurs identiques que l'on prenne \x_ij ou la version normalis√©e
         
    
    #-----------------------------------#
    st.markdown("#### Application")
    st.markdown("")
    
    var_cat1_cat2_xi = st.multiselect("S√©lectionnez deux variables cat√©gorielles( 'Code AGB', 'Nom du Produit en Fran√ßais', 'LCI Name' ont √©t√© supprim√©es)", 
                                         synthese_dataset.select_dtypes(object).drop(['Code AGB', 'Nom du Produit en Fran√ßais', 'LCI Name'], axis=1).columns,
                                         key="cat_1_cat2_xi") 
    
    if var_cat1_cat2_xi != []:
            cat1_xi = var_cat1_cat2_xi[0]
            cat2_xi = var_cat1_cat2_xi[1]
            # r√©cup√©rer la table de contingence et la table des xi_ij normalis√©e avec la fonction pr√©c√©dente
            cont, table = table_xi_normalisee(synthese_dataset, cat1_xi, cat2_xi)
            # afficher avec une heatmap 
            fig, ax = plt.subplots()
            sns.heatmap(table.iloc[:-1,:-1], ax=ax, annot=cont.iloc[:-1,:-1], fmt='.0f')    # on affiche toujours les effectifs, pas l'indicateur, qui est repr√©sent√© par la couleur 
                                                                                  # on enl√®ve les colonnes des totaux
            st.write(fig)
            
            st.markdown("""*Mmm ... Affichage √† am√©liorer :confused:*""")
    
  
    
  
    
  
#==============================   Page 3  ===================================#
#============= Pr√©-traitement des donn√©es - premiers mod√®les ================#

def page3():
    
    st.title("Pr√©-traitement des donn√©es - Premiers mod√®les - Mod√®le final")

    #-------------------------------------------------------------------------#    
    st.header("Donn√©es originales")
    
    @st.cache(persist=True)
    def load_data_bis():
        data_original = pd.read_csv("datasets/Agribalyse_Synthese.csv", header=0)
        return data_original
    
    data_original=load_data_bis()
    st.write(data_original)
    
    #----------------------------------#
    # Cr√©er une copie pour les modifications
    data_original_copy = data_original.copy()


    #*************************************************************************#
    #*************************************************************************#
    st.header("Pr√©-traitement des donn√©es")

    #----------------------------------#
    st.subheader("Cr√©ation du train set et du test set")
    
    agree_create_train_set_test_set = st.checkbox('Valider cette √©tape',
                                                  key="train_set_test_set")

    if agree_create_train_set_test_set:
        train_set, test_set = train_test_split(data_original, test_size=0.20, random_state=0)
        st.write('Ok !')
        st.markdown("*Train set*")
        st.write(train_set)
        st.markdown("*Format des donn√©es*")
        st.write(train_set.shape)

        #----------------------------------#
        st.subheader("Feature selection simple")
    
        var_to_delete_simple = st.multiselect("S√©lectionnez les variables √† supprimer", 
                                              data_original.columns,
                                              key="var_to_delete_simple ") 
        if var_to_delete_simple !=[]:
            data_original_copy = train_set.drop(var_to_delete_simple, axis=1)
            st.write(data_original_copy)

        #----------------------------------#
        st.subheader("Encodage des variables cat√©gorielles")
        
        encoding_mth = st.selectbox("S√©lectionnez la m√©thode d'encodage", 
                                    ["Label Encoding", "One-Hot Encoding","Binary Encoding"],
                                    key="encoding_mth") 
    
    
        if encoding_mth != None:
            # liste des colonnes type 'object'
            col_object = data_original_copy.select_dtypes(object).columns
            
            if encoding_mth=="Label Encoding":
                # cr√©er l'encodeur
                label_encoder = LabelEncoder()
                for col in col_object:
                    data_original_copy[col] = label_encoder.fit_transform(data_original_copy[col])
        
                # afficher le nouveau dataset
                st.markdown("*Train set apr√®s Label Encoding*")
                st.write(data_original_copy)
            
            elif encoding_mth=="One-Hot Encoding":
                # cr√©er l'encodeur
                OH_encoder = OneHotEncoder(sparse=False)
                
                # appliquer l'encodeur : cela retourne un array
                OH_array = OH_encoder.fit_transform(data_original_copy[col_object])
                # transformer en dataframe + rajouter les noms de colonnes
                OH_df = pd.DataFrame(OH_array)
                # remettre les bons index
                OH_df.index = data_original_copy.index
                # supprimer les colonnes 'object' du dataset initial
                df_initial_num = data_original_copy.drop(col_object, axis=1)
                # concat√©ner les deux dataframe
                data_original_copy = pd.concat([df_initial_num,OH_df], axis=1)
                # afficher le nouveau dataset
                st.markdown("*Train set apr√®s One-Hot Encoding*")
                st.write(data_original_copy)
            
            elif encoding_mth=="Binary Encoding":
                # cr√©er l'encodeur : on pr√©cise les colonnes √† encoder
                binary_encoder = ce.BinaryEncoder(cols=col_object)
                # appliquer l'encodeur √† nos donn√©es
                data_original_copy = binary_encoder.fit_transform(data_original_copy)
                # afficher le nouveau dataset
                st.markdown("*Train set apr√®s Binary Encoding*")
                st.write(data_original_copy)
            
            
        #----------------------------------#
        st.subheader("Donn√©es manquantes")
            
        st.write("Il n'y a aucune donn√©e manquante.")
        st.write(pd.DataFrame(data_original_copy.isna().sum()))
            
            
        #----------------------------------#
        st.subheader("Cr√©er X_train et y_train")
    
        
        agree_separate_X_y = st.checkbox('Valider cette √©tape',
                                         key="separate_X_y")

        if agree_separate_X_y:
            target = "DQR - Note de qualit√© de la donn√©e (1 excellente ; 5 tr√®s faible)"
            X_train = data_original_copy.drop(target,axis=1)
            y_train = data_original_copy[target]
            st.markdown("*X_train*")
            st.write(X_train)
            st.markdown("*Format des donn√©es*")
            st.write(X_train.shape)
            st.write('Ok !')
     
        
     
    #*************************************************************************#
    #*************************************************************************#
    st.header("Premiers mod√®les")
    
    #----------------------------------#
    st.subheader("Versions par d√©faut")
    
    st.markdown("""
                * On entra√Æne et on √©value les mod√®les dans leur version par d√©faut.
                * Outils :
                    * M√©triques :
                        * MAE
                        * MSE
                        * RMSE
                        * $R^2$
                    * Learning Curve : [doc1](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.learning_curve.html?highlight=learning#sklearn.model_selection.learning_curve), [doc2](https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html#sphx-glr-auto-examples-model-selection-plot-learning-curve-py)
                """)
    
    models_default_list = st.multiselect("S√©lectionnez les mod√®les", 
                                          ['Ridge', 'SVR', 'kNN'],
                                         key="modeles_defaut") 
    
    
    #-----------------#
    # on d√©finit une fonction pour tracer les Learning Curve
    # param√®tres :
    ## model : le mod√®le utilis√© pour l'√©valuation
    ## Xtrain, ytrain : donn√©es pour l'entra√Ænement
    ## cv : nombre de cross-validation
    ## scoring : la m√©trique utilis√© (donn√©e sous forme n√©gative)

    # output de 'learning curve' (il y en a 5 en tout, on n'en consid√®re que 3 ici)
    ## N : array des tailles des √©chantillons utilis√©es pour l'entra√Ænement
    ## train_score : array des scores pour chaque cross-validation, et chacun des √©chantillons d'entra√Ænement 
    ## val_score : m√™me chose pour les √©chantillons de validation

    # output de la fonction 'evaluation' : les learning curve (graphiques)
    
    def evaluation(model, Xtrain, ytrain, cv, scoring) :    
        # utilisation de la classe 'learning_curve'
        N, train_score, val_score = learning_curve(model,            
                                                   Xtrain, ytrain,
                                                   cv=cv,
                                                   scoring=scoring,
                                                   train_sizes=np.linspace(0.05,1,10))
    
        if scoring in ['neg_mean_absolute_error','neg_mean_squared_error','neg_root_mean_squared_error']:
            # tracer les learning curve
            fig, ax = plt.subplots()
            ax.plot(N, -train_score.mean(axis=1), label='train score')
            ax.plot(N, -val_score.mean(axis=1), label='validation score')
            # on rajoute une zone autour des courbes avec l'√©cart-type :
            # "courbe +/- √©cart-type"
            ax.fill_between(N, (-train_score).mean(axis=1) - (-train_score).std(axis=1),
                             (-train_score).mean(axis=1) + (-train_score).std(axis=1), alpha=0.1)
            ax.fill_between(N, (-val_score).mean(axis=1) - (-val_score).std(axis=1),
                             (-val_score).mean(axis=1) + (-val_score).std(axis=1), alpha=0.1)
            ax.legend()
            #ax.xlabel("Taille de l'ensemble d'entra√Ænement")
            st.pyplot(fig)
        else :
            # tracer les learning curve
            fig, ax = plt.subplots()
            ax.plot(N, train_score.mean(axis=1), label='train score')
            ax.plot(N, val_score.mean(axis=1), label='validation score')
            # on rajoute une zone autour des courbes avec l'√©cart-type :
            # "courbe +/- √©cart-type"
            ax.fill_between(N, (train_score).mean(axis=1) - (train_score).std(axis=1),
                             (train_score).mean(axis=1) + (train_score).std(axis=1), alpha=0.1)
            ax.fill_between(N, (val_score).mean(axis=1) - (val_score).std(axis=1),
                             (val_score).mean(axis=1) + (val_score).std(axis=1), alpha=0.1)
            ax.legend()
            #ax.xlabel("Taille de l'ensemble d'entra√Ænement")
            st.pyplot(fig)
    #-----------------#
    
    #-----------------#
    # liste des noms des mod√®les
    model_name = ['Ridge', 'SVR', 'kNN']
    # liste des scoring
    scoring_list = ['neg_mean_absolute_error','neg_mean_squared_error','neg_root_mean_squared_error', 'r2']
    # liste des noms des m√©triques
    metric_name = ['MAE', 'MSE', 'RMSE', 'R2']
    # taille de la cross-validation
    c_v = 4
    #-----------------#
    
    
    #-----------------#
    # Il faut d'abord entrainer les mod√®les s√©lectionner.
    # Ensuite, nous allons afficher les learning curve pour chaque m√©trique et chaque mod√®le.
    # Nous affichons les noms des m√©triques et des mod√®les utilis√©s en utilisant les listes 'model_name' et 'metric_name'.
    # (difficult√© √† int√©grer cela dans la fonction 'evaluation' ...)

    if models_default_list != []:
        for i,model in enumerate(models_default_list):
            if model=='Ridge':
                # definir le mod√®le 
                model_lin_ridge = Ridge()
                model_lin_ridge.fit(X_train,y_train)
                for j,sc in enumerate(scoring_list):
                    st.write('Ridge', metric_name[j])
                    evaluation(model_lin_ridge, 
                               X_train, y_train,
                               c_v,
                               scoring=sc)
            elif model=='SVR':
                # definir le mod√®le 
                model_svm_svr = SVR()
                model_svm_svr.fit(X_train,y_train)
                for j,sc in enumerate(scoring_list):
                    st.write('SVR', metric_name[j])
                    evaluation(model_svm_svr, 
                               X_train, y_train,
                               c_v,
                               scoring=sc)
            
            elif model=='kNN':
                # definir le mod√®le 
                model_knn_reg = KNeighborsRegressor()
                model_knn_reg.fit(X_train,y_train)
                for j,sc in enumerate(scoring_list):
                    st.write('SVR', metric_name[j])
                    evaluation(model_knn_reg, 
                               X_train, y_train,
                               c_v,
                               scoring=sc)
    
    #----------------------------------#
    st.subheader("Tentatives d'am√©lioration des mod√®les")
    # s√©lectionner un mod√®le + list selector pour hyperparam√®tres + feature enginerring + feature selection en pipelen ?
    model_to_improve = st.selectbox("S√©lectionnez un mod√®le de travail", 
                                          ['Ridge', 'SVR', 'kNN'],
                                         key="models_to_improve")
    
    if model_to_improve != None :
        if model_to_improve=='Ridge':
            #----------------------------------#
            st.write('#### Hyperparam√®tres')
            alpha_ridge = st.slider("S√©lectionner alpha",
                                    min_value=0.0,
                                    max_value=10.0, 
                                    step=0.01,
                                    value=1.0,
                                    key="alpha_ridge")
            # definir le mod√®le 
            model_lin_ridge = Ridge(alpha=alpha_ridge)
            # refit avec le nouveau Ridge()
            model_lin_ridge.fit(X_train,y_train)
            
            #-----------------#
            agree_reevaluate_ridge = st.checkbox('R√©evaluer le mod√®le ?',
                                                 key="reevaluate_ridge")
            
            if agree_reevaluate_ridge:
                for j,sc in enumerate(scoring_list):
                    st.write('Ridge', metric_name[j])
                    evaluation(model_lin_ridge, 
                               X_train, y_train,
                               c_v,
                               scoring=sc)
            #-----------------#
                    
            #----------------------------------#
            st.write('#### Feature Selection')
            
            feature_selection_list = st.multiselect("S√©lectionnez la m√©thode", 
                                                    ['VarianceThreshold'],
                                                    key="feature_selection_list")
            
            if feature_selection_list !=[]:
                for mth in feature_selection_list:
                    if mth=='VarianceThreshold':
                        # choisir le param√®tre 'threshold'
                        var_threshold = st.slider("S√©lectionner le 'threshold'", 
                                                  min_value=0.0, max_value=1.0,
                                                  step=0.01,
                                                  value=0.0,
                                                  key="var_threshold")
                        # d√©finir le selector
                        selector = VarianceThreshold(threshold=var_threshold)
                        # appliquer le selector aux donn√©es 'X_train'
                        # output : array
                        # on transforme en dataframe, en r√©cup√©rant les noms de colonnes
                        X_train_selected = pd.DataFrame(selector.fit_transform(X_train),
                                                        columns = X_train.columns[selector.get_support()])
                        # on r√©cup√®re les bons index
                        X_train_selected.index = X_train.index
                        # remplacer ces donn√©es dans 'X_train'
                        X_train = X_train_selected
                        # afficher les nouvelles donn√©es
                        st.markdown("Donn√©es avec VarianceThreshold")
                        st.write(X_train)
                        st.markdown("*Format des donn√©es*")
                        st.write(X_train.shape)
                        
                        #-----------------#
                        agree_reevaluate_var_threshold = st.checkbox('R√©evaluer le mod√®le ?',
                                                                      key="reevaluate_var_threshold")
            
                        if agree_reevaluate_var_threshold:
                            # definir le mod√®le 
                            model_lin_ridge = Ridge(alpha=alpha_ridge)
                            # refit avec les nouvelles donn√©es 'X_train'
                            model_lin_ridge.fit(X_train,y_train)
                            # r√©√©valuer
                            for j,sc in enumerate(scoring_list):
                                st.write('Ridge', metric_name[j])
                                evaluation(model_lin_ridge, 
                                           X_train, y_train,
                                           c_v,
                                           scoring=sc)
                        #-----------------#
                
                
            #----------------------------------#
            st.write('#### Feature Engineering')
            
            feature_engineering_list = st.multiselect("S√©lectionner la m√©thode",
                                                      ["StandardScaler"],
                                                      key='feature_engineering')
            
            if feature_engineering_list != []:
                for mth in feature_engineering_list:
                    if mth=="StandardScaler":
                        # d√©finition du StandardScaler
                        scaler = StandardScaler()
                        # colonnes √† standardiser
                        standard_columns = st.multiselect("S√©lectionner les colonnes √† utiliser",
                                                      X_train.columns,
                                                      key='standard_columns')
                        
                        if standard_columns !=[]:
                            # on applique le scaler aux colonnes concern√©es : cela retourne un array
                            # on le transforme en un dataframe, en rajoutant les noms de colonne perdus
                            # on r√©cup√®re les bons index (ceux de X_train)
                            standard_array = scaler.fit_transform(X_train[standard_columns])
                            df_standardized = pd.DataFrame(standard_array, columns=standard_columns)
                            df_standardized.index = X_train.index
                            # on remplace les colonnes concern√©es par le dataframe pr√©c√©dent 'df_standardized'
                            X_train[standard_columns] = df_standardized
                            # afficher les nouvelles donn√©es
                            st.write(X_train)
                            
                            
                            #-----------------#
                            agree_reevaluate_std_scaler = st.checkbox('R√©evaluer le mod√®le ?',
                                                                      key="reevaluate_std_scaler")
            
                            if agree_reevaluate_std_scaler:
                                # definir le mod√®le 
                                model_lin_ridge = Ridge(alpha=alpha_ridge)
                                # refit avec les nouvelles donn√©es 'X_train'
                                model_lin_ridge.fit(X_train,y_train)
                                # r√©√©valuer
                                for j,sc in enumerate(scoring_list):
                                    st.write('Ridge', metric_name[j])
                                    evaluation(model_lin_ridge, 
                                               X_train, y_train,
                                               c_v,
                                               scoring=sc)
                            #-----------------#
                
                
            
        elif model_to_improve=='SVR':
            st.markdown('en construction :construction:')
        else:
            st.markdown('en construction :construction:')
    
    #*************************************************************************#
    #*************************************************************************#
    st.header("Mod√®le final")
    st.markdown('en construction :construction:')
    
    #----------------------------------#
    st.subheader("Fine-tuning des mod√®les prometteurs")
    st.markdown('en construction :construction:')


    #----------------------------------#
    st.subheader("Evaluation sur le Test set")
    st.markdown('en construction :construction:')

    #----------------------------------#
    #st.subheader("Sauvegarder le mod√®le")

#########################################################
if __name__=="__main__":
    main()









